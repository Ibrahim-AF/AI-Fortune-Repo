{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week4.4 - Introductory Machine Learning Class assignment Learning Credit Information.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBK2UwrZbCFG"
      },
      "source": [
        "# **[Problem 1] Confirmation of competition contents**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzGhOX3TbzGG"
      },
      "source": [
        "* **What to learn and what to predic?**\r\n",
        "\r\n",
        "This prompt us to learn about the **Transaction Information** relative to the ***clients*** and to be able to Predict the **Payment Abilities**  of the ***clients***. This is relative to the probability for the TARGET variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0vmNZsLdT10"
      },
      "source": [
        "* **What kind of file to create and submit to Kaggle?**\r\n",
        "\r\n",
        "For each **SK_ID_CURR** in the test set, you must be able to predict a probability for the **TARGET** variable. \r\n",
        "\r\n",
        "**NOTE:** The file should contain a header and have the following format: **SK_ID_CURR,TARGET**\r\n",
        "* 100001,0.1\r\n",
        "* 100005,0.9\r\n",
        "* 100013,0.2 etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlY8_UaFeiYs"
      },
      "source": [
        "* **What kind of index value will be used to evaluate the submissions?**\r\n",
        "\r\n",
        "The submissions are evaluated on area under the **Receiver Operating Characteristic(ROC) curve** between the predicted probability and the observed target."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xke3pRcAfR_z"
      },
      "source": [
        "# **[Problem 2] Learning and verification**\r\n",
        "\r\n",
        "* We import all needed libraries\r\n",
        "* Load the Data (application_train.csv)\r\n",
        "* Delete the Null data(empty data)\r\n",
        "* Extract or separate them into variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2_I2Uu0fgU2"
      },
      "source": [
        "import pandas as pd\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import mean_squared_error\r\n",
        "from sklearn.linear_model import LinearRegression\r\n",
        "from sklearn.metrics import roc_auc_score\r\n",
        "\r\n",
        "\r\n",
        "df = pd.read_csv('application_train.csv')\r\n",
        "\r\n",
        "\r\n",
        "cleaned_df = df.dropna()\r\n",
        "\r\n",
        "\r\n",
        "X = cleaned_df.loc[:,[\"AMT_INCOME_TOTAL\",\"AMT_CREDIT\",\"AMT_ANNUITY\"]]\r\n",
        "y = cleaned_df['TARGET']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "9xVTdL0-gwTI",
        "outputId": "6e571638-5643-4f4d-d25d-7e1e3161f5d4"
      },
      "source": [
        "df.head()#loading the data"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SK_ID_CURR</th>\n",
              "      <th>TARGET</th>\n",
              "      <th>NAME_CONTRACT_TYPE</th>\n",
              "      <th>CODE_GENDER</th>\n",
              "      <th>FLAG_OWN_CAR</th>\n",
              "      <th>FLAG_OWN_REALTY</th>\n",
              "      <th>CNT_CHILDREN</th>\n",
              "      <th>AMT_INCOME_TOTAL</th>\n",
              "      <th>AMT_CREDIT</th>\n",
              "      <th>AMT_ANNUITY</th>\n",
              "      <th>AMT_GOODS_PRICE</th>\n",
              "      <th>NAME_TYPE_SUITE</th>\n",
              "      <th>NAME_INCOME_TYPE</th>\n",
              "      <th>NAME_EDUCATION_TYPE</th>\n",
              "      <th>NAME_FAMILY_STATUS</th>\n",
              "      <th>NAME_HOUSING_TYPE</th>\n",
              "      <th>REGION_POPULATION_RELATIVE</th>\n",
              "      <th>DAYS_BIRTH</th>\n",
              "      <th>DAYS_EMPLOYED</th>\n",
              "      <th>DAYS_REGISTRATION</th>\n",
              "      <th>DAYS_ID_PUBLISH</th>\n",
              "      <th>OWN_CAR_AGE</th>\n",
              "      <th>FLAG_MOBIL</th>\n",
              "      <th>FLAG_EMP_PHONE</th>\n",
              "      <th>FLAG_WORK_PHONE</th>\n",
              "      <th>FLAG_CONT_MOBILE</th>\n",
              "      <th>FLAG_PHONE</th>\n",
              "      <th>FLAG_EMAIL</th>\n",
              "      <th>OCCUPATION_TYPE</th>\n",
              "      <th>CNT_FAM_MEMBERS</th>\n",
              "      <th>REGION_RATING_CLIENT</th>\n",
              "      <th>REGION_RATING_CLIENT_W_CITY</th>\n",
              "      <th>WEEKDAY_APPR_PROCESS_START</th>\n",
              "      <th>HOUR_APPR_PROCESS_START</th>\n",
              "      <th>REG_REGION_NOT_LIVE_REGION</th>\n",
              "      <th>REG_REGION_NOT_WORK_REGION</th>\n",
              "      <th>LIVE_REGION_NOT_WORK_REGION</th>\n",
              "      <th>REG_CITY_NOT_LIVE_CITY</th>\n",
              "      <th>REG_CITY_NOT_WORK_CITY</th>\n",
              "      <th>LIVE_CITY_NOT_WORK_CITY</th>\n",
              "      <th>...</th>\n",
              "      <th>LIVINGAPARTMENTS_MEDI</th>\n",
              "      <th>LIVINGAREA_MEDI</th>\n",
              "      <th>NONLIVINGAPARTMENTS_MEDI</th>\n",
              "      <th>NONLIVINGAREA_MEDI</th>\n",
              "      <th>FONDKAPREMONT_MODE</th>\n",
              "      <th>HOUSETYPE_MODE</th>\n",
              "      <th>TOTALAREA_MODE</th>\n",
              "      <th>WALLSMATERIAL_MODE</th>\n",
              "      <th>EMERGENCYSTATE_MODE</th>\n",
              "      <th>OBS_30_CNT_SOCIAL_CIRCLE</th>\n",
              "      <th>DEF_30_CNT_SOCIAL_CIRCLE</th>\n",
              "      <th>OBS_60_CNT_SOCIAL_CIRCLE</th>\n",
              "      <th>DEF_60_CNT_SOCIAL_CIRCLE</th>\n",
              "      <th>DAYS_LAST_PHONE_CHANGE</th>\n",
              "      <th>FLAG_DOCUMENT_2</th>\n",
              "      <th>FLAG_DOCUMENT_3</th>\n",
              "      <th>FLAG_DOCUMENT_4</th>\n",
              "      <th>FLAG_DOCUMENT_5</th>\n",
              "      <th>FLAG_DOCUMENT_6</th>\n",
              "      <th>FLAG_DOCUMENT_7</th>\n",
              "      <th>FLAG_DOCUMENT_8</th>\n",
              "      <th>FLAG_DOCUMENT_9</th>\n",
              "      <th>FLAG_DOCUMENT_10</th>\n",
              "      <th>FLAG_DOCUMENT_11</th>\n",
              "      <th>FLAG_DOCUMENT_12</th>\n",
              "      <th>FLAG_DOCUMENT_13</th>\n",
              "      <th>FLAG_DOCUMENT_14</th>\n",
              "      <th>FLAG_DOCUMENT_15</th>\n",
              "      <th>FLAG_DOCUMENT_16</th>\n",
              "      <th>FLAG_DOCUMENT_17</th>\n",
              "      <th>FLAG_DOCUMENT_18</th>\n",
              "      <th>FLAG_DOCUMENT_19</th>\n",
              "      <th>FLAG_DOCUMENT_20</th>\n",
              "      <th>FLAG_DOCUMENT_21</th>\n",
              "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
              "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
              "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
              "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
              "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
              "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100002</td>\n",
              "      <td>1</td>\n",
              "      <td>Cash loans</td>\n",
              "      <td>M</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>202500.0</td>\n",
              "      <td>406597.5</td>\n",
              "      <td>24700.5</td>\n",
              "      <td>351000.0</td>\n",
              "      <td>Unaccompanied</td>\n",
              "      <td>Working</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Single / not married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>0.018801</td>\n",
              "      <td>-9461</td>\n",
              "      <td>-637</td>\n",
              "      <td>-3648.0</td>\n",
              "      <td>-2120</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Laborers</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>WEDNESDAY</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0193</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>reg oper account</td>\n",
              "      <td>block of flats</td>\n",
              "      <td>0.0149</td>\n",
              "      <td>Stone, brick</td>\n",
              "      <td>No</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-1134.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100003</td>\n",
              "      <td>0</td>\n",
              "      <td>Cash loans</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>270000.0</td>\n",
              "      <td>1293502.5</td>\n",
              "      <td>35698.5</td>\n",
              "      <td>1129500.0</td>\n",
              "      <td>Family</td>\n",
              "      <td>State servant</td>\n",
              "      <td>Higher education</td>\n",
              "      <td>Married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>0.003541</td>\n",
              "      <td>-16765</td>\n",
              "      <td>-1188</td>\n",
              "      <td>-1186.0</td>\n",
              "      <td>-291</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Core staff</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>MONDAY</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0787</td>\n",
              "      <td>0.0558</td>\n",
              "      <td>0.0039</td>\n",
              "      <td>0.01</td>\n",
              "      <td>reg oper account</td>\n",
              "      <td>block of flats</td>\n",
              "      <td>0.0714</td>\n",
              "      <td>Block</td>\n",
              "      <td>No</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-828.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100004</td>\n",
              "      <td>0</td>\n",
              "      <td>Revolving loans</td>\n",
              "      <td>M</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>67500.0</td>\n",
              "      <td>135000.0</td>\n",
              "      <td>6750.0</td>\n",
              "      <td>135000.0</td>\n",
              "      <td>Unaccompanied</td>\n",
              "      <td>Working</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Single / not married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>0.010032</td>\n",
              "      <td>-19046</td>\n",
              "      <td>-225</td>\n",
              "      <td>-4260.0</td>\n",
              "      <td>-2531</td>\n",
              "      <td>26.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Laborers</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>MONDAY</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-815.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100006</td>\n",
              "      <td>0</td>\n",
              "      <td>Cash loans</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>135000.0</td>\n",
              "      <td>312682.5</td>\n",
              "      <td>29686.5</td>\n",
              "      <td>297000.0</td>\n",
              "      <td>Unaccompanied</td>\n",
              "      <td>Working</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Civil marriage</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>0.008019</td>\n",
              "      <td>-19005</td>\n",
              "      <td>-3039</td>\n",
              "      <td>-9833.0</td>\n",
              "      <td>-2437</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Laborers</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>WEDNESDAY</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-617.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100007</td>\n",
              "      <td>0</td>\n",
              "      <td>Cash loans</td>\n",
              "      <td>M</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>121500.0</td>\n",
              "      <td>513000.0</td>\n",
              "      <td>21865.5</td>\n",
              "      <td>513000.0</td>\n",
              "      <td>Unaccompanied</td>\n",
              "      <td>Working</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Single / not married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>0.028663</td>\n",
              "      <td>-19932</td>\n",
              "      <td>-3038</td>\n",
              "      <td>-4311.0</td>\n",
              "      <td>-3458</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Core staff</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>THURSDAY</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1106.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 122 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   SK_ID_CURR  TARGET  ... AMT_REQ_CREDIT_BUREAU_QRT AMT_REQ_CREDIT_BUREAU_YEAR\n",
              "0      100002       1  ...                       0.0                        1.0\n",
              "1      100003       0  ...                       0.0                        0.0\n",
              "2      100004       0  ...                       0.0                        0.0\n",
              "3      100006       0  ...                       NaN                        NaN\n",
              "4      100007       0  ...                       0.0                        0.0\n",
              "\n",
              "[5 rows x 122 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ld4pNJSCg0_u"
      },
      "source": [
        "**We split the data into traning and testing data (sklearn)**\r\n",
        "\r\n",
        "* Standardizing it\r\n",
        "* fit and predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZErLcOSWhEXu",
        "outputId": "3af5cf3f-b60e-4a91-de22-cd32ed566856"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\r\n",
        "\r\n",
        "scaler = StandardScaler()\r\n",
        "scaler.fit(X_train)\r\n",
        "X_train_trans = scaler.transform(X_train)\r\n",
        "X_test_trans = scaler.transform(X_test)\r\n",
        "\r\n",
        "reg = LinearRegression().fit(X_train_trans, y_train)\r\n",
        "\r\n",
        "reg_pred = reg.predict(X_test_trans)\r\n",
        "\r\n",
        "print(\"MSE:\", mean_squared_error(y_true=y_test, y_pred=reg_pred))\r\n",
        "print(\"ROC\", roc_auc_score(y_test,reg_pred))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE: 0.0567142335416132\n",
            "ROC 0.5245983935742973\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3cn0n_8hP4X"
      },
      "source": [
        "**MSE** is very low which is a good indication"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I03tmQoxhXaZ"
      },
      "source": [
        "# **[Problem 3] Estimation on test data**\r\n",
        "\r\n",
        "* Perform the estimation on the test data (application_test.csv ) and submit it to Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jo025B91he7F"
      },
      "source": [
        "test_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7HTi0-IhvdD"
      },
      "source": [
        "test_df = pd.read_csv('application_test.csv')\r\n",
        "\r\n",
        "test_cleaned_df = test_df.dropna(axis=0)\r\n",
        "\r\n",
        "test_X = test_cleaned_df.loc[:,[\"AMT_INCOME_TOTAL\",\"AMT_CREDIT\",\"AMT_ANNUITY\"]]\r\n",
        "\r\n",
        "test_scaler = StandardScaler()\r\n",
        "test_X_test_trans = scaler.fit_transform(test_X)\r\n",
        "\r\n",
        "test_reg_pred = reg.predict(test_X_test_trans)\r\n",
        "#submitting to kaggle\r\n",
        "kgl_submission = pd.concat([test_df['SK_ID_CURR'], pd.Series(test_reg_pred, name='TARGET')], axis=1)\r\n",
        "kgl_submission = kgl_submission.fillna(0)\r\n",
        "kgl_submission.at[648,'TARGET']= 0\r\n",
        "kgl_submission.shape\r\n",
        "kgl_submission.to_csv('kggl_submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVZ2NZSth0cI"
      },
      "source": [
        "# **[Problem 4] Feature engineering**\r\n",
        "\r\n",
        "To improve accuracy, perform Feature Engineering from the following perspectives.\r\n",
        "* Which feature to use?\r\n",
        "* How to preprocess?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blSSW1IEiT0I"
      },
      "source": [
        "**Pattern 1 of training and validation.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Cguh7pJia5m"
      },
      "source": [
        "# imputation\r\n",
        "import numpy as np\r\n",
        "from sklearn.impute import SimpleImputer\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "\r\n",
        "imp_mean = SimpleImputer(strategy='mean')\r\n",
        "\r\n",
        "# deleting the missing values\r\n",
        "imp_X = imp_mean.fit_transform(X)\r\n",
        "\r\n",
        "# One hot encoding\r\n",
        "from sklearn.preprocessing import OneHotEncoder\r\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\r\n",
        "enc_imp_X = enc.fit_transform(imp_X).toarray()\r\n",
        "\r\n",
        "# splitting the data into training and testing data using train_test_split from sklearn\r\n",
        "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(enc_imp_X, y, test_size=0.25, random_state=42)\r\n",
        "\r\n",
        "# we standardized the data\r\n",
        "scaler = StandardScaler()\r\n",
        "scaler.fit(X_train_1)\r\n",
        "X_train_trans_1 = scaler.transform(X_train_1)\r\n",
        "X_test_trans_1 = scaler.transform(X_test_1)\r\n",
        "\r\n",
        "# fitting the data\r\n",
        "from lightgbm import LGBMClassifier\r\n",
        "lgbm = LGBMClassifier(random_state=5)\r\n",
        "lgb = lgbm.fit(X_train_trans_1, y_train_1)\r\n",
        "\r\n",
        "# predicting\r\n",
        "reg_pred_1 = lgb.predict(X_test_trans_1)\r\n",
        "\r\n",
        "print(\"Accuracy: \", accuracy_score(y_test_1,reg_pred_1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSQUxujfim34"
      },
      "source": [
        "**Pattern 2 of training and validation.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeHtRlhsiqYn"
      },
      "source": [
        "imp_median = SimpleImputer(strategy='median')\r\n",
        "\r\n",
        "# deleting the missing values\r\n",
        "imp_X_1 = imp_median.fit_transform(X)\r\n",
        "\r\n",
        "# One hot encoding\r\n",
        "from sklearn.preprocessing import OneHotEncoder\r\n",
        "enc_1 = OneHotEncoder(handle_unknown='ignore')\r\n",
        "enc_imp_X_1 = enc.fit_transform(imp_X_1).toarray()\r\n",
        "\r\n",
        "# splitting the data into training and testing data using train_test_split from sklearn\r\n",
        "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(enc_imp_X_1, y, test_size=0.25, random_state=42)\r\n",
        "\r\n",
        "# we standardized the data\r\n",
        "scaler = StandardScaler()\r\n",
        "scaler.fit(X_train_2)\r\n",
        "X_train_trans_2 = scaler.transform(X_train_2)\r\n",
        "X_test_trans_2 = scaler.transform(X_test_2)\r\n",
        "\r\n",
        "# fitting the data\r\n",
        "from lightgbm import LGBMClassifier\r\n",
        "lgbm_1 = LGBMClassifier(random_state=5)\r\n",
        "lgb_1 = lgbm_1.fit(X_train_trans_2, y_train_2)\r\n",
        "\r\n",
        "# predicting\r\n",
        "reg_pred_2 = lgb_1.predict(X_test_trans_2)\r\n",
        "\r\n",
        "print(\"Accuracy: \", accuracy_score(y_test_2,reg_pred_2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SErQCsOxiuPn"
      },
      "source": [
        "**Pattern 3 of training and validation.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8crZfBti1Lr"
      },
      "source": [
        "imp_mf = SimpleImputer(strategy='most_frequent')\r\n",
        "\r\n",
        "# deleting the missing values\r\n",
        "imp_X_2 = imp_mf.fit_transform(X)\r\n",
        "\r\n",
        "# One hot encoding\r\n",
        "from sklearn.preprocessing import OneHotEncoder\r\n",
        "enc_2 = OneHotEncoder(handle_unknown='ignore')\r\n",
        "enc_imp_X_2 = enc.fit_transform(imp_X_2).toarray()\r\n",
        "\r\n",
        "# splitting the data into training and testing data using train_test_split from sklearn\r\n",
        "X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(enc_imp_X_2, y, test_size=0.25, random_state=42)\r\n",
        "\r\n",
        "# we standardized the data\r\n",
        "scaler = StandardScaler()\r\n",
        "scaler.fit(X_train_3)\r\n",
        "X_train_trans_3 = scaler.transform(X_train_3)\r\n",
        "X_test_trans_3 = scaler.transform(X_test_3)\r\n",
        "\r\n",
        "# fitting the data\r\n",
        "from lightgbm import LGBMClassifier\r\n",
        "lgbm_2 = LGBMClassifier(random_state=5)\r\n",
        "lgb_2 = lgbm_2.fit(X_train_trans_3, y_train_3)\r\n",
        "\r\n",
        "# predicting\r\n",
        "reg_pred_3 = lgb_2.predict(X_test_trans_3)\r\n",
        "\r\n",
        "print(\"Accuracy: \", accuracy_score(y_test_3,reg_pred_3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZuoBRMGi4kj"
      },
      "source": [
        "**Pattern 4 of training and validation.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pJBa9Iti-r9"
      },
      "source": [
        "imp_cnst = SimpleImputer(strategy='constant')\r\n",
        "\r\n",
        "# deleting the missing values\r\n",
        "imp_X_3 = imp_cnst.fit_transform(X)\r\n",
        "\r\n",
        "# One hot encoding\r\n",
        "from sklearn.preprocessing import OneHotEncoder\r\n",
        "enc_3 = OneHotEncoder(handle_unknown='ignore')\r\n",
        "enc_imp_X_3 = enc.fit_transform(imp_X_3).toarray()\r\n",
        "\r\n",
        "# splitting the data into training and testing data using train_test_split from sklearn\r\n",
        "X_train_4, X_test_4, y_train_4, y_test_4 = train_test_split(enc_imp_X_3, y, test_size=0.25, random_state=42)\r\n",
        "\r\n",
        "# we standardized the data\r\n",
        "scaler = StandardScaler()\r\n",
        "scaler.fit(X_train_4)\r\n",
        "X_train_trans_4 = scaler.transform(X_train_4)\r\n",
        "X_test_trans_4 = scaler.transform(X_test_4)\r\n",
        "\r\n",
        "# fitting the data\r\n",
        "from lightgbm import LGBMClassifier\r\n",
        "lgbm_3 = LGBMClassifier(random_state=5)\r\n",
        "lgb_3 = lgbm_3.fit(X_train_trans_4, y_train_4)\r\n",
        "\r\n",
        "# predicting\r\n",
        "reg_pred_4 = lgb_3.predict(X_test_trans_4)\r\n",
        "\r\n",
        "print(\"Accuracy: \", accuracy_score(y_test_4,reg_pred_4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTcEua54jEdx"
      },
      "source": [
        "**Pattern 5 of training and validation.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4V2D1kdMjH17"
      },
      "source": [
        "imp_cnst = SimpleImputer(strategy='constant')\r\n",
        "\r\n",
        "# deleting the missing values\r\n",
        "imp_X_4 = imp_cnst.fit_transform(X)\r\n",
        "\r\n",
        "# One hot encoding\r\n",
        "from sklearn.preprocessing import OneHotEncoder\r\n",
        "enc_4 = OneHotEncoder(handle_unknown='ignore')\r\n",
        "enc_imp_X_4 = enc.fit_transform(imp_X_4).toarray()\r\n",
        "\r\n",
        "# splitting the data into training and testing data using train_test_split from sklearn\r\n",
        "X_train_5, X_test_5, y_train_5, y_test_5 = train_test_split(enc_imp_X_4, y, test_size=0.25, random_state=42)\r\n",
        "\r\n",
        "# we standardizied data\r\n",
        "scaler = StandardScaler()\r\n",
        "scaler.fit(X_train_5)\r\n",
        "X_train_trans_5 = scaler.transform(X_train_5)\r\n",
        "X_test_trans_5 = scaler.transform(X_test_5)\r\n",
        "\r\n",
        "# fitting the data\r\n",
        "from lightgbm import LGBMClassifier\r\n",
        "lgbm_4 = LGBMClassifier(random_state=5)\r\n",
        "lgb_4 = lgbm_4.fit(X_train_trans_5, y_train_5)\r\n",
        "\r\n",
        "# predicting\r\n",
        "reg_pred_5 = lgb_4.predict(X_test_trans_5)\r\n",
        "\r\n",
        "print(\"Accuracy: \", accuracy_score(y_test_5,reg_pred_5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dy0qbbcKjV82"
      },
      "source": [
        "* **The feature and preprocess used is** IMPUTAION and HOT ENCODING **techniques**.\r\n",
        "* **These techniques are more useful, and from what is noticed, when using simple imputer the accuracy will still be high and they also stays constant.**"
      ]
    }
  ]
}